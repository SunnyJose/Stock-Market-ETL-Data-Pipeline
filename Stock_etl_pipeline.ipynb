{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f152887-f5e6-4e24-b27c-07d5cc05444a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.9 (dt dec pq3 ext lo64)\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "print(psycopg2.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edc01dee-c673-4ffd-ba96-cb4751c8fd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "localhost\n",
      "5432\n",
      "postgres\n",
      "stocks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getenv(\"DB_HOST\"))\n",
    "print(os.getenv(\"DB_PORT\"))\n",
    "print(os.getenv(\"DB_USER\"))\n",
    "print(os.getenv(\"DB_NAME\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21de7759-383b-42c4-9d05-65b0de122680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = get_engine()\n",
    "engine.connect().close()\n",
    "print(\"Connection successful\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "585201f7-dddb-4383-bceb-26161c852f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postgres connection works\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "\n",
    "engine = create_engine(\n",
    "    f\"postgresql+psycopg2://{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@\"\n",
    "    f\"{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/{os.getenv('DB_NAME')}\"\n",
    ")\n",
    "\n",
    "engine.connect().close()\n",
    "print(\"Postgres connection works\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "597cbad4-062c-45c8-90a5-5022c16a95cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = get_engine()\n",
    "engine.connect().close()\n",
    "print(\"Connection successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4373accb-59ca-4dde-a156-177c709ed4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.39\n",
      "2.9.11 (dt dec pq3 ext lo64)\n"
     ]
    }
   ],
   "source": [
    "import sqlalchemy\n",
    "import psycopg2\n",
    "\n",
    "print(sqlalchemy.__version__)\n",
    "print(psycopg2.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "583fa3af-7ec2-446e-b481-47df054b2eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "localhost\n",
      "5432\n",
      "postgres\n",
      "stocks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.getenv(\"DB_HOST\"))\n",
    "print(os.getenv(\"DB_PORT\"))\n",
    "print(os.getenv(\"DB_USER\"))\n",
    "print(os.getenv(\"DB_NAME\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56700f69-6989-4f24-ad70-3efce1d1da8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is AAPL ETL data pipeline from 2020 to 2025\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from datetime import timedelta\n",
    "import os\n",
    "\n",
    "TICKER = \"AAPL\"\n",
    "START_DATE = \"2020-01-01\"\n",
    "END_DATE = \"2025-12-31\"\n",
    "\n",
    "\n",
    "def get_engine():\n",
    "    required = [\n",
    "        \"DB_HOST\",\n",
    "        \"DB_PORT\",\n",
    "        \"DB_USER\",\n",
    "        \"DB_PASSWORD\",\n",
    "        \"DB_NAME\",\n",
    "    ]\n",
    "\n",
    "    missing = [v for v in required if not os.getenv(v)]\n",
    "    if missing:\n",
    "        raise RuntimeError(f\"Missing env vars: {missing}\")\n",
    "\n",
    "    return create_engine(\n",
    "        f\"postgresql+psycopg2://\"\n",
    "        f\"{os.getenv('DB_USER')}:{os.getenv('DB_PASSWORD')}@\"\n",
    "        f\"{os.getenv('DB_HOST')}:{os.getenv('DB_PORT')}/\"\n",
    "        f\"{os.getenv('DB_NAME')}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def get_last_loaded_date(engine):\n",
    "    query = text(\"\"\"\n",
    "        SELECT last_loaded_date\n",
    "        FROM etl_metadata\n",
    "        WHERE ticker = :ticker\n",
    "    \"\"\")\n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(query, {\"ticker\": TICKER}).fetchone()\n",
    "        return result[0] if result else None\n",
    "\n",
    "\n",
    "def update_last_loaded_date(engine, last_date):\n",
    "    query = text(\"\"\"\n",
    "        INSERT INTO etl_metadata (ticker, last_loaded_date)\n",
    "        VALUES (:ticker, :last_date)\n",
    "        ON CONFLICT (ticker)\n",
    "        DO UPDATE SET last_loaded_date = EXCLUDED.last_loaded_date\n",
    "    \"\"\")\n",
    "\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(\n",
    "            query,\n",
    "            {\"ticker\": TICKER, \"last_date\": last_date}\n",
    "        )\n",
    "\n",
    "\n",
    "def extract_data(start_date):\n",
    "    df = yf.download(\n",
    "        TICKER,\n",
    "        start=start_date,\n",
    "        end=END_DATE,\n",
    "        interval=\"1d\"\n",
    "    )\n",
    "    return df.reset_index()\n",
    "\n",
    "\n",
    "def transform_data(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    if isinstance(df.columns, pd.MultiIndex):\n",
    "        df.columns = df.columns.get_level_values(0)\n",
    "\n",
    "    df[\"ticker\"] = TICKER\n",
    "\n",
    "    if \"Adj Close\" in df.columns:\n",
    "        df[\"adj_close\"] = df[\"Adj Close\"]\n",
    "    else:\n",
    "        df[\"adj_close\"] = df[\"Close\"]\n",
    "\n",
    "    df[\"daily_return\"] = df[\"adj_close\"].pct_change()\n",
    "    df[\"ma_20\"] = df[\"adj_close\"].rolling(20).mean()\n",
    "\n",
    "    df.rename(\n",
    "        columns={\n",
    "            \"Date\": \"trade_date\",\n",
    "            \"Open\": \"open\",\n",
    "            \"High\": \"high\",\n",
    "            \"Low\": \"low\",\n",
    "            \"Close\": \"close\",\n",
    "            \"Volume\": \"volume\"\n",
    "        },\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    return df[\n",
    "        [\n",
    "            \"trade_date\",\n",
    "            \"ticker\",\n",
    "            \"open\",\n",
    "            \"high\",\n",
    "            \"low\",\n",
    "            \"close\",\n",
    "            \"adj_close\",\n",
    "            \"volume\",\n",
    "            \"daily_return\",\n",
    "            \"ma_20\"\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "\n",
    "def validate_data(df):\n",
    "    if df.empty:\n",
    "        raise ValueError(\"No data extracted\")\n",
    "\n",
    "    if df[\"trade_date\"].isnull().any():\n",
    "        raise ValueError(\"Null trade_date detected\")\n",
    "\n",
    "    if df[\"close\"].isnull().any():\n",
    "        raise ValueError(\"Null close prices detected\")\n",
    "\n",
    "    if df[\"adj_close\"].isnull().any():\n",
    "        raise ValueError(\"Null adjusted close detected\")\n",
    "\n",
    "    if (df[\"volume\"] < 0).any():\n",
    "        raise ValueError(\"Negative volume detected\")\n",
    "\n",
    "def load_data(engine, df):\n",
    "    df.to_sql(\n",
    "        \"daily_prices\",\n",
    "        engine,\n",
    "        if_exists=\"append\",\n",
    "        index=False,\n",
    "        method=\"multi\"\n",
    "    )\n",
    "\n",
    "\n",
    "def run_pipeline():\n",
    "    engine = get_engine()\n",
    "\n",
    "    last_date = get_last_loaded_date(engine)\n",
    "\n",
    "    start_date = (\n",
    "        last_date + timedelta(days=1)\n",
    "        if last_date\n",
    "        else START_DATE\n",
    "    )\n",
    "\n",
    "    raw = extract_data(start_date)\n",
    "\n",
    "    if raw.empty:\n",
    "        print(f\"No data found for {TICKER} starting {start_date}. Skipping load.\")\n",
    "        return\n",
    "\n",
    "    clean = transform_data(raw)\n",
    "    validate_data(clean)\n",
    "    load_data(engine, clean)\n",
    "\n",
    "    update_last_loaded_date(\n",
    "        engine,\n",
    "        clean[\"trade_date\"].max()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de08e88b-721d-4ab6-83e2-9bd99fffe34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   trade_date ticker       open       high        low      close  adj_close  \\\n",
      "0  2020-01-02   AAPL  71.476615  72.528597  71.223274  72.468277  72.468277   \n",
      "1  2020-01-03   AAPL  71.696183  72.523769  71.539352  71.763741  71.763741   \n",
      "2  2020-01-06   AAPL  70.885472  72.374162  70.634539  72.335556  72.335556   \n",
      "3  2020-01-07   AAPL  72.345197  72.600952  71.775781  71.995346  71.995346   \n",
      "4  2020-01-08   AAPL  71.698589  73.455103  71.698589  73.153503  73.153503   \n",
      "5  2020-01-09   AAPL  74.130683  74.900365  73.879757  74.707344  74.707344   \n",
      "6  2020-01-10   AAPL  74.941386  75.440836  74.374378  74.876236  74.876236   \n",
      "7  2020-01-13   AAPL  75.192306  76.502451  75.074074  76.475906  76.475906   \n",
      "8  2020-01-14   AAPL  76.413185  76.623097  75.320190  75.443237  75.443237   \n",
      "9  2020-01-15   AAPL  75.242997  76.123665  74.688049  75.119942  75.119942   \n",
      "\n",
      "      volume  daily_return ma_20             load_timestamp  \n",
      "0  135480400           NaN  None 2026-01-27 00:50:08.982442  \n",
      "1  146322800     -0.009722  None 2026-01-27 00:50:08.982442  \n",
      "2  118387200      0.007968  None 2026-01-27 00:50:08.982442  \n",
      "3  108872000     -0.004703  None 2026-01-27 00:50:08.982442  \n",
      "4  132079200      0.016087  None 2026-01-27 00:50:08.982442  \n",
      "5  170108400      0.021241  None 2026-01-27 00:50:08.982442  \n",
      "6  140644800      0.002261  None 2026-01-27 00:50:08.982442  \n",
      "7  121532000      0.021364  None 2026-01-27 00:50:08.982442  \n",
      "8  161954400     -0.013503  None 2026-01-27 00:50:08.982442  \n",
      "9  121923600     -0.004285  None 2026-01-27 00:50:08.982442  \n",
      "Total rows: 1507\n",
      "Latest trade_date: 2025-12-30\n"
     ]
    }
   ],
   "source": [
    "#This check if the data made it to the postgres database\n",
    "\n",
    "from sqlalchemy import text\n",
    "import pandas as pd\n",
    "\n",
    "engine = get_engine()\n",
    "\n",
    "# Fetch first 10 rows\n",
    "df = pd.read_sql(text(\"SELECT * FROM daily_prices LIMIT 10\"), engine)\n",
    "print(df)\n",
    "\n",
    "# Count total rows\n",
    "total_rows = pd.read_sql(text(\"SELECT COUNT(*) FROM daily_prices\"), engine)\n",
    "print(\"Total rows:\", total_rows.iloc[0, 0])\n",
    "\n",
    "# Latest trade date\n",
    "latest_date = pd.read_sql(text(\"SELECT MAX(trade_date) FROM daily_prices\"), engine)\n",
    "print(\"Latest trade_date:\", latest_date.iloc[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bbebd27c-1709-43d4-819d-58d0fdb90493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Daily Prices Summary by Ticker ===\n",
      "  ticker  total_rows  first_date   last_date  min_adj_close  max_adj_close\n",
      "0   AAPL        1507  2020-01-02  2025-12-30      54.264336     286.190002\n"
     ]
    }
   ],
   "source": [
    "#This verify the daily_price table, and see a summary of each ticker\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "from datetime import datetime\n",
    "\n",
    "engine = get_engine()  # reuse your existing get_engine function\n",
    "\n",
    "# Fetch all tickers with basic stats\n",
    "query = text(\"\"\"\n",
    "    SELECT\n",
    "        ticker,\n",
    "        COUNT(*) AS total_rows,\n",
    "        MIN(trade_date) AS first_date,\n",
    "        MAX(trade_date) AS last_date,\n",
    "        MIN(adj_close) AS min_adj_close,\n",
    "        MAX(adj_close) AS max_adj_close\n",
    "    FROM daily_prices\n",
    "    GROUP BY ticker\n",
    "    ORDER BY ticker\n",
    "\"\"\")\n",
    "\n",
    "df_summary = pd.read_sql(query, engine)\n",
    "\n",
    "print(\"=== Daily Prices Summary by Ticker ===\")\n",
    "print(df_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7dcc4f-ea47-49de-a9c1-cff449c66f97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
